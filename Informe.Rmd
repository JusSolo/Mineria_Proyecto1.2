---
title: "Proyecto1"
author:
- "Juan Luis Solórzano (carnet: 201598)"
- - "Micaela Yataz (carnet: 18960)"
date: "2025-01-20"
output: pdf_document
---






```{r paquetes necesarios, message=FALSE,warning=FALSE, echo=FALSE}
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(dplyr)
library(flexclust)
if (!requireNamespace("tidyr", quietly = TRUE)) install.packages("tidyr")
library(tidyr)

```

```{r cargar datos,  echo=FALSE}
#datos <- read.csv('movies.csv')
#datos <- read.csv('movies.csv',stringsAsFactors = F)

datos<-read.csv("movies.csv", stringsAsFactors = F)

summary(datos)
```



# 1. Clustering
## 1.1. Haga el preprocesamiento del dataset, explique qué variables no aportan información a la generación de grupos y por qué. Describa con qué variables calculará los grupos.
Como el algoritmo de k-medias y el clustering jerárquico necesitan de alguna medida de distancia, entre los datos, en una primera instancia vamos a tomas solo las variables numéricas y vamos a quitar el id por ser como el nombre de una película. Las variables que tomaremos en consideración son las siguientes:


```{r, tomando variables cuantitativas, echo=FALSE}

datos_num <- datos %>%
  select(where(~ is.integer(.) | is.numeric(.)))

datos_num <- datos_num[,2:11]
str(datos_num)

 

```

```{r Revisando los datos y variables, include=FALSE}
datos_num <- scale(datos_num)
summary(datos_num)
```


## 1.2. Analice la tendencia al agrupamiento usando el estadístico de Hopkings y la VAT (Visual Assessment of cluster Tendency). Esta última hágala si es posible, teniendo en cuenta las dimensiones del conjunto de datos. Discuta sus resultados e impresiones.

```{r hopkins, echo=FALSE}
set.seed(155)
estadisticoHop <- hopkins(datos_num)
```
El estadístico de Hopkings es de `r estadisticoHop ` que es lejano a 0.5, entonces los datos no son aleatorios. Sin embargo no haremos un VAT por ser difícil de visualizar e interpretar con 10 variables. 

## 1.3. Determine cuál es el número de grupos a formar más adecuado para los datos que está trabajando. Haga una gráfica de codo y explique la razón de la elección de la cantidad de clústeres con la que trabajará.

Para ello se usará el metodo de Codo

```{r codo, echo=FALSE, warning=FALSE, fig.width=6, fig.height=4, dpi=300}
set.seed(940) 
wss=0
for (i in 1:10) 
  wss[i] <- sum(kmeans(datos_num, centers=i)$withinss)

plot(1:10, wss, type="b", xlab="Número de grupos",  ylab="suma de cuadrados intragrupo")
```

Como a partir de 3 grupos en adelante la suma de cuadrados intragrupo no disminuye tan rápido se elegirán 3 grupos. 

## 1.4. Utilice los algoritmos k-medias y clustering jerárquico para agrupar. Compare los resultados generados por cada uno.



```{r kmedias con k 3, echo=FALSE}
 
set.seed(102)
kmeans_result <- kmeans(datos_num, centers=3)

```



```{r jerárquico, echo=FALSE}
#Matriz de distncias
D <- dist(datos_num)

hc<-hclust(D, method = "ward.D2") #Genera el clustering jerÃ¡rquico de los datos

plot(hc, cex=0.5, axes=FALSE) #Genera el dendograma
rect.hclust(hc,k=3)
grupos <- cutree(hc, k = 3)

```


```{r comparar agrupamientos, echo=FALSE}
plotcluster(datos_num, kmeans_result$cluster)
title(main="Clusters generados por K-means")



```

```{r el otro resultado, echo=FALSE}
plotcluster(datos_num, grupos)
title(main="Clusters generados por Clustering Jerárquico")
```




## 1.5. Determine la calidad del agrupamiento hecho por cada algoritmo con el método de la silueta. Discuta los resultados.

```{r sillueta kmedias , echo=FALSE}
library(cluster)
sil_kmeans <- silhouette(kmeans_result$cluster, D)
sil_hc <- silhouette(grupos, D)


plot(sil_kmeans, main="Silueta K-means",cex.names=.4, col=1:3)


```


```{r silueta jerárquico,  echo=FALSE, message=FALSE, warning=FALSE}
plot(sil_hc, main="Silueta Clustering Jerárquico", ,cex.names=.4, col=1:3)
```


Usando el método de la silueta el clustering jerárquico que tiene una silueta promedio de $0.35 > 0.15$ del clustering de Kmedias. Entonces para estos datos el clusterin jerárqioco obtubo un mejor resultado. Esto tiene sentido pues en la entrega anterior vimos que ninguna variable se comportaba de manera normal. En estos casos el k-medias no suele ser tan eficiente. 


## 1.6. Interprete los grupos basado en el conocimiento que tiene de los datos. Recuerde investigar las medidas de tendencia central de las variables continuas y las tablas de frecuencia de las variables categóricas pertenecientes a cada grupo. Identifique hallazgos interesantes debido a las agrupaciones y describa para qué le podría servir.
```{r saparar df por clusters, echo=FALSE}
# Asegurar que las variables de cluster están en el dataframe y son factores
datos <- datos %>%
  mutate(Cluster_KMeans = factor(kmeans_result$cluster),
         Cluster_Jerarquico = factor(grupos))

# Crear los 6 dataframes
df_kmeans_1 <- datos %>% filter(Cluster_KMeans == "1")
df_kmeans_2 <- datos %>% filter(Cluster_KMeans == "2")
df_kmeans_3 <- datos %>% filter(Cluster_KMeans == "3")

df_jerarquico_1 <- datos %>% filter(Cluster_Jerarquico == "1")
df_jerarquico_2 <- datos %>% filter(Cluster_Jerarquico == "2")
df_jerarquico_3 <- datos %>% filter(Cluster_Jerarquico == "3")

# Mostrar la cantidad de observaciones en cada cluster
cat("Tamaños de los dataframes:\n")
cat("K-Means -> Cluster 1:", nrow(df_kmeans_1), " | Cluster 2:", nrow(df_kmeans_2), " | Cluster 3:", nrow(df_kmeans_3), "\n")
cat("Jerárquico -> Cluster 1:", nrow(df_jerarquico_1), " | Cluster 2:", nrow(df_jerarquico_2), " | Cluster 3:", nrow(df_jerarquico_3), "\n")


```

Como es dificil interpretar los numeros puros vamos a hacer unas gráficas de caja y bigote.

```{r caja y bigote kmedias, echo=FALSE}

# Variables clave
variables <- c("budget", "revenue", "popularity", "voteAvg", "voteCount", "runtime")

# Unificar los datos para K-Means
df_kmeans <- datos %>% 
  select(Cluster_KMeans, all_of(variables)) %>% 
  pivot_longer(cols = all_of(variables), names_to = "Variable", values_to = "Valor")

# Unificar los datos para Clustering Jerárquico
df_jerarquico <- datos %>% 
  select(Cluster_Jerarquico, all_of(variables)) %>% 
  pivot_longer(cols = all_of(variables), names_to = "Variable", values_to = "Valor")

# Crear función para gráficos de caja
plot_boxplot <- function(df, cluster_col, title) {
  ggplot(df, aes(x = factor(!!sym(cluster_col)), y = Valor, fill = factor(!!sym(cluster_col)))) +
    geom_boxplot(outlier.shape = NA, alpha = 0.7) +
    facet_wrap(~ Variable, scales = "free_y") + 
    scale_y_log10() +  # Escala logarítmica para mejor visualización
    labs(x = "Cluster", y = "Valor", title = title, fill = "Cluster") +
    theme_minimal() +
    theme(legend.position = "none")
}

# Graficar K-Means
plot_boxplot(df_kmeans, "Cluster_KMeans", "Distribución de Variables por Clusters (K-Means)")

# Graficar Clustering Jerárquico


```

#### Clusters generados por K-Means:

    El grupo 1: Presenta valores intermedios en presupuesto, recaudación y popularidad. Probablemente incluya películas comerciales de mediano éxito.
    El grupo 2: Contiene películas con los presupuestos y recaudaciones más altos, alta popularidad y una gran cantidad de votos. Es probable que sean grandes producciones o éxitos de taquilla.
    El grupo 3: Se caracteriza por películas con presupuestos y recaudaciones bajas, menor popularidad y pocos votos. Parece representar películas independientes o de bajo presupuesto.


```{r caja y bigote jerarquico, echo=FALSE}
plot_boxplot(df_jerarquico, "Cluster_Jerarquico", "Distribución de Variables por Clusters (Jerárquico)")
```

#### Clusters generados por Clustering Jerárquico:

    El grupo 1: Incluye películas con recaudación y presupuesto moderado,  popularidad mas bien baja.
    El grupo 2: Peliculas de alto presupuesto, altas recaudacion y popularidad
    El grupo 3: Agrupa peliculas de bajo presupuesto, con popularidades relativamente bajas y recaudaciones muy dispersas. 
    
  




# 2. Reglas de Asociación
2.1. Obtenga reglas de asociación interesantes del conjunto de datos usando el algoritmo “A
priori”. Recuerde discretizar las variables numéricas. Genere reglas con diferentes niveles
de confianza y soporte. Discuta los resultados. Si considera que debe eliminar variables

```{r otras librerias , echo=FALSE, warning=FALSE}
library(arules)
library(dplyr)
library(arulesViz)
```


```{r preparando los datos para apriori, cache=FALSE, echo=FALSE}
datosD <- datos %>%
  mutate(across(where(is.character), as.factor)) %>%
  mutate(across(where(is.numeric), discretize))
trans <- as(datos,"transactions")

```


```{r ejecutando aprioris,include=FALSE }

# Definir valores de soporte y confianza
soporter <- c(.12,.22,.28, .35, .50)
confianzas <- c(.4, .60, .85)

# Crear un data frame vacío para almacenar los resultados
resultados <- data.frame(Soporte = numeric(),
                         Confianza = numeric(),
                         Num_Reglas = integer())

# Bucle anidado para probar todas las combinaciones
for (s in soporter) {
  for (c in confianzas) {
    # Generar reglas con los parámetros actuales
    reglas <- apriori(trans, parameter = list(support = s, 
                                              confidence = c, 
                                              target = "rules", 
                                              minlen = 3, maxlen = 7))
   
    resultados <- rbind(resultados, data.frame(Soporte = s, 
                                               Confianza = c, 
                                               Num_Reglas = length(reglas)))
  }
}

# Mostrar la tabla con los resultados


# También puedes ordenarlo por número de reglas si lo deseas
resultados <- arrange(resultados, desc(Num_Reglas))


```


```{r mapa de calor del numero de reglas}
library(ggplot2)

# Crear el gráfico de calor
ggplot(resultados, aes(x = factor(Soporte), y = factor(Confianza), fill = Num_Reglas)) +
  geom_tile() +
  geom_text(aes(label = Num_Reglas), color = "white", size = 5) + 
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Cantidad de Reglas Generadas", 
       x = "Soporte", 
       y = "Confianza", 
       fill = "N° de Reglas") +
  theme_minimal()

```
Con el mapa de calor de el numero de reglas tenemos una idea de que soporte y confianza es buena idea elegir.Para discutir sobre las variables que mas importan para las reglas y las que menos vamos a elegir un soporte de 30% y una confianza de 60%

```{r  message=FALSE,warning=FALSE,echo=FALSE}
reglas <- apriori(trans, parameter = list(support = s, 
                                              confidence = c, 
                                              target = "rules", 
                                              minlen = 3, maxlen = 7))
inspect(reglas)
```
Sorpresa, a la base de datos le agregue las etiquetas de los clusters. La mayoria de regras tienen algo que ver con el cluster jerárquico 1 . Pero las reglas tienen intervalos muy grandes, tanto que no aportan conocimineto relevante Yo quitaría esa variable. 


# 3 Análisis de componentes Principales

## Estudia la matriz de correlación, la agrega y explica lo que observa en ella

En el analisis se realiza a patir de una muestra de datos de 10000 peliculas obtenidos de la plataforma The movie DB. Se evalua la correlacion entre variables. Se presentan las varibales que se incuyen en el analisis:

Indice de popularidad de la película
Presupuesto de la película
Ingreso de la película
Duración de la película
Cantidad de géneros que representan la película
Cantidad de companias productoras que participaron en la película
Cantidad de paises que se llevó a cabo la pelicula 
Número de votos en la platadorma de la película
Promedio de votos en la plataforma de la película
Índice de popularidad del elenco de la película
Cantidad de personas que actúan en la película
Cantidad de actrices en el elenco de la película
Cantidad de actores en el elenco de la película.





```{r setup, include=FALSE}

library(dplyr)
library(ggplot2)
library(GGally)

library(psych)
library(FactoMineR)
library(fpc)
library(factoextra)
library(corrplot)
library(PCAmixdata)
library(paran)
```



```{r eleccion}
datos$castWomenAmount<- as.numeric(datos$castWomenAmount)
datos$castMenAmount<- as.numeric(datos$castMenAmount)
datos$actorsPopularity <-as.character(datos$actorsPopularity)
datos$actorsPopularity<- strsplit(datos$actorsPopularity, "\\|")
datos$actorsPopularity<-lapply(datos$actorsPopularity, as.numeric, use = "pairwise.complete.obs")
datos$actorsPopularity<- sapply(datos$actorsPopularity, function(x) if (all(is.na(x))) NA else mean(x, na.rm = TRUE))
datos$actorsPopularity<- sapply(datos$actorsPopularity, function(x) { 
  if (all(is.na(x))) { 
    return(NA)  # Si todos son NA, el promedio es NA
  } else { 
    return(mean(x, na.rm = TRUE))  # Calcular la media sin contar los NA
  }
})
  
sub_datos<-datos[, c("popularity", "budget", "revenue", "runtime", "genresAmount", "productionCoAmount", "productionCountriesAmount", "voteCount", "voteAvg", "castWomenAmount", "castMenAmount" )]
matriz_cor <- cor(sub_datos, use = "pairwise.complete.obs" )
determinante<-det(matriz_cor)
```




La determinante es 
```{r ver determinantes}
print(determinante)
```

indicando que las variabes estan relacionadas entre si 

#Determina si es posible usar la técnica de análisis factorial para hallar las componentes
principales

```{r kmo}
KMO(as.matrix(sub_datos))
```
El indice es de 0.67 lo cual es un valor regular, es suficiente pero no el ideal.

#• Determina si vale la pena aplicar las componentes principales interpretando la prueba de
esfericidad de Bartlett

```{r cortes }
cortest.bartlett(sub_datos)
```
Como P=0 por lo que se rechaza la hipotesis nula, implicando que el analisis factorial es apropiado.

#• Obtiene los componentes principales y explica cuántos seleccionará para explicar la mayor variabilidad posible.

```{r matriz de correlacion}
matriz_cor <- cor(sub_datos, use = "pairwise.complete.obs" )
corrplot(matriz_cor)
```
Segun la tabla vemos que la variable del presupuesto de la pelicula se correlaciona con ingreso de pelicula, asi mismo con el numero de votos en la plataforma.
El numero de votos en la plataforma con el ingreso de la pelicula tambien estan correlacionados.
El numero de actores en el elenco de las peliculas esta relacionado con la cantidad de paises en los que se rodo la pelicula.

#• Interpreta los coeficientes principales.


```{r PCA}

pca_result<-princomp(covmat=matriz_cor,use = "pairwise.complete.obs" )
#compPrinc<-prcomp(sub_datos, scale = T, use = "pairwise.complete.obs")
#compPrinc
summary(pca_result)

```
#regla de Kaiser

```{r}
valores_propios<-pca_result$sdev^2
valores_propios
```
Tomamos los 4 componentes principales.

```{r screeplot}
fviz_eig(pca_result, addlabels = TRUE, ylim = c(0, 80))
fviz_eig(pca_result, addlabels = TRUE, choice = c("eigenvalue"), ylim = c(0, 3))

```

Interpretacion: 
EL componenete 1 se relaciona con el exito comercial y popularidad de la pelicula, las peliculas con alto presupuesto alto ingreso, y votaciones tienen valores altos en este componente.

El componente 2, puede indicar la cantidad de actores en el elenco pueden estar asociados con los paises productores.

El componente 3, inidica un mayor numero de mujeres en el elenco tienden a tener menor puntuacion.

El componente 4, Los valores altos podriamos relacionarlo con las peliculas independientes, es decir con menos productoras.





  
    



